# @package _global_

env:
  name: LorlEnv-v0
  type: "lorl"
  task: "open drawer"
  use_state: True
  sparse: True
  normalize: True
  binary_reward: False
  reward_multiplier: 1000

training:
  log_freq: 1000  # Log every these many env steps
  save_model_freq: 0 # Save networks every these many episodes
  eval_freq: 1000 # eval every these many env steps.

agent:
  value_loss_coeff: 0.05
  n_layers: 3
  hidden_size: 128