# @package _global_

env:
  name: LorlEnv-v0
  type: "lorl"
  task: "open drawer"
  use_state: True
  sparse: False
  normalize: True
  reward_multiplier: 1000
  max_steps: 20

training:
  max_training_episodes: 20000
  log_freq: 100  # Log every these many episodes
  save_model_freq: 0 # Save networks every these many episodes
  eval_freq: 250 # eval every these many episodes
  num_eval_eps: 10

agent:
  value_loss_coeff: 0.05
  n_layers: 3
  hidden_size: 128
  hca_n_layers: 2
  hca_hidden_size: 128
  hca_update_every: 500
  hca_num_updates: 5
  refresh_hca: True