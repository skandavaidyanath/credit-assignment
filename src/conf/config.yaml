defaults:
  # Set default options
  - _self_
  - env: lorl_state
  - agent: ppo

hydra_base_dir: ""

training:
  wandb: True
  device: ""
  max_training_episodes: 1000000 # some big number
  seed: 0
  checkpoint: ""
  exp_name_modifier: ""
  collect_hca_data: False
  hca_data_save_freq: 1000

env:
  gamma: 0.99

agent:
  update_every: 50
  ppo_epochs: 30
  minibatch_size: 64
  eps_clip: 0.2
  clip_range_vf: null # no value function clipping by default
  lamda: 0.95
  entropy_coeff: 0.0
  value_loss_coeff: 0.25
  n_layers: 2
  hidden_size: 64
  lr: 3e-4
  activation_fn: "relu"
  max_grad_norm: null # no gradient norm clipping by default
